{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQnElZkBaEDSlIExVwoX6N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52183/2303a52183-GEN-AI-2025/blob/main/gen_ai_ass_7_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqHXf7K184v3",
        "outputId": "54064fff-ce86-42b7-e728-f88bf2e18f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.3976 - loss: 0.7431 - val_accuracy: 0.3486 - val_loss: 0.7412\n",
            "Epoch 2/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3708 - loss: 0.6988 - val_accuracy: 0.3486 - val_loss: 0.7184\n",
            "Epoch 3/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4091 - loss: 0.6840 - val_accuracy: 0.3394 - val_loss: 0.7003\n",
            "Epoch 4/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3865 - loss: 0.7130 - val_accuracy: 0.3486 - val_loss: 0.6847\n",
            "Epoch 5/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3255 - loss: 0.6895 - val_accuracy: 0.3303 - val_loss: 0.6708\n",
            "Epoch 6/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3868 - loss: 0.6631 - val_accuracy: 0.3303 - val_loss: 0.6580\n",
            "Epoch 7/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3630 - loss: 0.6339 - val_accuracy: 0.3303 - val_loss: 0.6460\n",
            "Epoch 8/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3736 - loss: 0.6420 - val_accuracy: 0.3303 - val_loss: 0.6354\n",
            "Epoch 9/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3633 - loss: 0.6321 - val_accuracy: 0.3394 - val_loss: 0.6254\n",
            "Epoch 10/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3911 - loss: 0.6061 - val_accuracy: 0.3394 - val_loss: 0.6160\n",
            "Epoch 11/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3645 - loss: 0.6253 - val_accuracy: 0.3394 - val_loss: 0.6070\n",
            "Epoch 12/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3790 - loss: 0.6084 - val_accuracy: 0.3486 - val_loss: 0.5979\n",
            "Epoch 13/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3737 - loss: 0.5932 - val_accuracy: 0.3486 - val_loss: 0.5895\n",
            "Epoch 14/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4162 - loss: 0.5870 - val_accuracy: 0.3486 - val_loss: 0.5813\n",
            "Epoch 15/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4002 - loss: 0.5896 - val_accuracy: 0.3394 - val_loss: 0.5735\n",
            "Epoch 16/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4338 - loss: 0.5807 - val_accuracy: 0.3394 - val_loss: 0.5657\n",
            "Epoch 17/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4184 - loss: 0.5515 - val_accuracy: 0.3394 - val_loss: 0.5584\n",
            "Epoch 18/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3608 - loss: 0.5702 - val_accuracy: 0.3394 - val_loss: 0.5513\n",
            "Epoch 19/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4147 - loss: 0.5405 - val_accuracy: 0.3486 - val_loss: 0.5441\n",
            "Epoch 20/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4085 - loss: 0.5684 - val_accuracy: 0.3394 - val_loss: 0.5370\n",
            "Epoch 21/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3877 - loss: 0.5331 - val_accuracy: 0.3394 - val_loss: 0.5304\n",
            "Epoch 22/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4356 - loss: 0.5400 - val_accuracy: 0.3486 - val_loss: 0.5236\n",
            "Epoch 23/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4033 - loss: 0.5621 - val_accuracy: 0.3578 - val_loss: 0.5168\n",
            "Epoch 24/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4417 - loss: 0.5173 - val_accuracy: 0.3486 - val_loss: 0.5101\n",
            "Epoch 25/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4078 - loss: 0.5150 - val_accuracy: 0.3486 - val_loss: 0.5038\n",
            "Epoch 26/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4186 - loss: 0.5091 - val_accuracy: 0.3578 - val_loss: 0.4974\n",
            "Epoch 27/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4258 - loss: 0.4747 - val_accuracy: 0.3578 - val_loss: 0.4912\n",
            "Epoch 28/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4501 - loss: 0.5144 - val_accuracy: 0.3578 - val_loss: 0.4848\n",
            "Epoch 29/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3776 - loss: 0.4790 - val_accuracy: 0.3486 - val_loss: 0.4786\n",
            "Epoch 30/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4541 - loss: 0.4761 - val_accuracy: 0.3486 - val_loss: 0.4723\n",
            "Epoch 31/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4259 - loss: 0.5476 - val_accuracy: 0.3486 - val_loss: 0.4660\n",
            "Epoch 32/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4393 - loss: 0.4766 - val_accuracy: 0.3486 - val_loss: 0.4598\n",
            "Epoch 33/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4102 - loss: 0.4765 - val_accuracy: 0.3486 - val_loss: 0.4538\n",
            "Epoch 34/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4530 - loss: 0.4852 - val_accuracy: 0.3486 - val_loss: 0.4477\n",
            "Epoch 35/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3680 - loss: 0.4228 - val_accuracy: 0.3578 - val_loss: 0.4415\n",
            "Epoch 36/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4392 - loss: 0.4349 - val_accuracy: 0.3578 - val_loss: 0.4355\n",
            "Epoch 37/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4411 - loss: 0.4459 - val_accuracy: 0.3578 - val_loss: 0.4294\n",
            "Epoch 38/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4378 - loss: 0.4765 - val_accuracy: 0.3578 - val_loss: 0.4234\n",
            "Epoch 39/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3764 - loss: 0.4052 - val_accuracy: 0.3578 - val_loss: 0.4175\n",
            "Epoch 40/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3980 - loss: 0.4079 - val_accuracy: 0.3578 - val_loss: 0.4116\n",
            "Epoch 41/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4171 - loss: 0.4196 - val_accuracy: 0.3578 - val_loss: 0.4058\n",
            "Epoch 42/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4211 - loss: 0.3967 - val_accuracy: 0.3670 - val_loss: 0.4000\n",
            "Epoch 43/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4564 - loss: 0.4277 - val_accuracy: 0.3670 - val_loss: 0.3939\n",
            "Epoch 44/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4373 - loss: 0.4490 - val_accuracy: 0.3578 - val_loss: 0.3880\n",
            "Epoch 45/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4220 - loss: 0.3801 - val_accuracy: 0.3578 - val_loss: 0.3821\n",
            "Epoch 46/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4168 - loss: 0.4186 - val_accuracy: 0.3578 - val_loss: 0.3761\n",
            "Epoch 47/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4398 - loss: 0.4127 - val_accuracy: 0.3578 - val_loss: 0.3701\n",
            "Epoch 48/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4396 - loss: 0.4074 - val_accuracy: 0.3578 - val_loss: 0.3641\n",
            "Epoch 49/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4045 - loss: 0.4253 - val_accuracy: 0.3578 - val_loss: 0.3581\n",
            "Epoch 50/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4312 - loss: 0.3433 - val_accuracy: 0.3578 - val_loss: 0.3524\n",
            "Epoch 51/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4484 - loss: 0.3509 - val_accuracy: 0.3578 - val_loss: 0.3468\n",
            "Epoch 52/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3879 - loss: 0.3913 - val_accuracy: 0.3578 - val_loss: 0.3408\n",
            "Epoch 53/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4455 - loss: 0.3247 - val_accuracy: 0.3578 - val_loss: 0.3347\n",
            "Epoch 54/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4384 - loss: 0.3752 - val_accuracy: 0.3578 - val_loss: 0.3288\n",
            "Epoch 55/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4059 - loss: 0.3375 - val_accuracy: 0.3578 - val_loss: 0.3228\n",
            "Epoch 56/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4354 - loss: 0.3151 - val_accuracy: 0.3578 - val_loss: 0.3172\n",
            "Epoch 57/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4194 - loss: 0.3912 - val_accuracy: 0.3578 - val_loss: 0.3115\n",
            "Epoch 58/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4187 - loss: 0.3489 - val_accuracy: 0.3578 - val_loss: 0.3057\n",
            "Epoch 59/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4687 - loss: 0.3397 - val_accuracy: 0.3578 - val_loss: 0.3002\n",
            "Epoch 60/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3920 - loss: 0.2933 - val_accuracy: 0.3486 - val_loss: 0.2946\n",
            "Epoch 61/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4091 - loss: 0.3033 - val_accuracy: 0.3486 - val_loss: 0.2891\n",
            "Epoch 62/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4159 - loss: 0.3229 - val_accuracy: 0.3486 - val_loss: 0.2835\n",
            "Epoch 63/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4231 - loss: 0.3081 - val_accuracy: 0.3486 - val_loss: 0.2777\n",
            "Epoch 64/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4558 - loss: 0.2715 - val_accuracy: 0.3486 - val_loss: 0.2719\n",
            "Epoch 65/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4490 - loss: 0.3115 - val_accuracy: 0.3486 - val_loss: 0.2662\n",
            "Epoch 66/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4139 - loss: 0.3663 - val_accuracy: 0.3486 - val_loss: 0.2606\n",
            "Epoch 67/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4729 - loss: 0.2963 - val_accuracy: 0.3486 - val_loss: 0.2551\n",
            "Epoch 68/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4557 - loss: 0.3052 - val_accuracy: 0.3486 - val_loss: 0.2495\n",
            "Epoch 69/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4361 - loss: 0.2774 - val_accuracy: 0.3486 - val_loss: 0.2439\n",
            "Epoch 70/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4326 - loss: 0.2992 - val_accuracy: 0.3486 - val_loss: 0.2383\n",
            "Epoch 71/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4270 - loss: 0.2867 - val_accuracy: 0.3486 - val_loss: 0.2329\n",
            "Epoch 72/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4110 - loss: 0.2992 - val_accuracy: 0.3486 - val_loss: 0.2271\n",
            "Epoch 73/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4489 - loss: 0.2420 - val_accuracy: 0.3486 - val_loss: 0.2214\n",
            "Epoch 74/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4502 - loss: 0.2338 - val_accuracy: 0.3486 - val_loss: 0.2153\n",
            "Epoch 75/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4189 - loss: 0.2517 - val_accuracy: 0.3486 - val_loss: 0.2095\n",
            "Epoch 76/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4300 - loss: 0.2353 - val_accuracy: 0.3486 - val_loss: 0.2038\n",
            "Epoch 77/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4207 - loss: 0.2190 - val_accuracy: 0.3486 - val_loss: 0.1984\n",
            "Epoch 78/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4238 - loss: 0.2464 - val_accuracy: 0.3486 - val_loss: 0.1930\n",
            "Epoch 79/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4342 - loss: 0.2812 - val_accuracy: 0.3486 - val_loss: 0.1875\n",
            "Epoch 80/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4102 - loss: 0.2257 - val_accuracy: 0.3486 - val_loss: 0.1820\n",
            "Epoch 81/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4149 - loss: 0.2259 - val_accuracy: 0.3486 - val_loss: 0.1767\n",
            "Epoch 82/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4326 - loss: 0.2538 - val_accuracy: 0.3394 - val_loss: 0.1713\n",
            "Epoch 83/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4564 - loss: 0.2611 - val_accuracy: 0.3394 - val_loss: 0.1657\n",
            "Epoch 84/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4569 - loss: 0.2180 - val_accuracy: 0.3394 - val_loss: 0.1607\n",
            "Epoch 85/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4322 - loss: 0.2023 - val_accuracy: 0.3394 - val_loss: 0.1551\n",
            "Epoch 86/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4234 - loss: 0.2342 - val_accuracy: 0.3394 - val_loss: 0.1493\n",
            "Epoch 87/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4454 - loss: 0.2856 - val_accuracy: 0.3394 - val_loss: 0.1434\n",
            "Epoch 88/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4574 - loss: 0.2275 - val_accuracy: 0.3394 - val_loss: 0.1378\n",
            "Epoch 89/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4365 - loss: 0.1741 - val_accuracy: 0.3394 - val_loss: 0.1324\n",
            "Epoch 90/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4542 - loss: 0.1325 - val_accuracy: 0.3394 - val_loss: 0.1269\n",
            "Epoch 91/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4128 - loss: 0.1638 - val_accuracy: 0.3394 - val_loss: 0.1215\n",
            "Epoch 92/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4536 - loss: 0.1931 - val_accuracy: 0.3394 - val_loss: 0.1161\n",
            "Epoch 93/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4455 - loss: 0.1741 - val_accuracy: 0.3394 - val_loss: 0.1109\n",
            "Epoch 94/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4614 - loss: 0.1441 - val_accuracy: 0.3394 - val_loss: 0.1052\n",
            "Epoch 95/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4735 - loss: 0.1597 - val_accuracy: 0.3394 - val_loss: 0.1001\n",
            "Epoch 96/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4430 - loss: 0.1493 - val_accuracy: 0.3394 - val_loss: 0.0946\n",
            "Epoch 97/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4456 - loss: 0.0848 - val_accuracy: 0.3394 - val_loss: 0.0895\n",
            "Epoch 98/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4086 - loss: 0.1456 - val_accuracy: 0.3394 - val_loss: 0.0843\n",
            "Epoch 99/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4339 - loss: 0.1412 - val_accuracy: 0.3394 - val_loss: 0.0790\n",
            "Epoch 100/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4349 - loss: 0.1516 - val_accuracy: 0.3394 - val_loss: 0.0736\n",
            "Epoch 101/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4398 - loss: 0.1513 - val_accuracy: 0.3394 - val_loss: 0.0684\n",
            "Epoch 102/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4373 - loss: 0.1748 - val_accuracy: 0.3394 - val_loss: 0.0632\n",
            "Epoch 103/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4362 - loss: 0.0481 - val_accuracy: 0.3394 - val_loss: 0.0577\n",
            "Epoch 104/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4013 - loss: 0.0556 - val_accuracy: 0.3394 - val_loss: 0.0525\n",
            "Epoch 105/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4535 - loss: 0.2144 - val_accuracy: 0.3394 - val_loss: 0.0471\n",
            "Epoch 106/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4531 - loss: 0.1495 - val_accuracy: 0.3394 - val_loss: 0.0420\n",
            "Epoch 107/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4208 - loss: 0.1694 - val_accuracy: 0.3394 - val_loss: 0.0366\n",
            "Epoch 108/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4287 - loss: 0.1698 - val_accuracy: 0.3394 - val_loss: 0.0312\n",
            "Epoch 109/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4396 - loss: 0.1030 - val_accuracy: 0.3394 - val_loss: 0.0258\n",
            "Epoch 110/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4356 - loss: 0.0054 - val_accuracy: 0.3394 - val_loss: 0.0207\n",
            "Epoch 111/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4398 - loss: 0.0134 - val_accuracy: 0.3394 - val_loss: 0.0154\n",
            "Epoch 112/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4262 - loss: 0.0506 - val_accuracy: 0.3394 - val_loss: 0.0101\n",
            "Epoch 113/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4431 - loss: 0.1382 - val_accuracy: 0.3394 - val_loss: 0.0049\n",
            "Epoch 114/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4066 - loss: 0.0524 - val_accuracy: 0.3486 - val_loss: -2.3292e-04\n",
            "Epoch 115/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4393 - loss: 0.0239 - val_accuracy: 0.3486 - val_loss: -0.0054\n",
            "Epoch 116/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4551 - loss: 0.0689 - val_accuracy: 0.3486 - val_loss: -0.0114\n",
            "Epoch 117/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4102 - loss: 0.0601 - val_accuracy: 0.3486 - val_loss: -0.0166\n",
            "Epoch 118/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4440 - loss: 0.0938 - val_accuracy: 0.3486 - val_loss: -0.0218\n",
            "Epoch 119/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4242 - loss: 0.0455 - val_accuracy: 0.3486 - val_loss: -0.0269\n",
            "Epoch 120/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4291 - loss: 0.0380 - val_accuracy: 0.3486 - val_loss: -0.0322\n",
            "Epoch 121/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4860 - loss: 0.0277 - val_accuracy: 0.3486 - val_loss: -0.0369\n",
            "Epoch 122/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4407 - loss: 0.0109 - val_accuracy: 0.3486 - val_loss: -0.0423\n",
            "Epoch 123/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4401 - loss: 0.0957 - val_accuracy: 0.3486 - val_loss: -0.0475\n",
            "Epoch 124/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4255 - loss: 0.0851 - val_accuracy: 0.3486 - val_loss: -0.0526\n",
            "Epoch 125/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3983 - loss: 0.0334 - val_accuracy: 0.3486 - val_loss: -0.0575\n",
            "Epoch 126/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4638 - loss: -0.0051 - val_accuracy: 0.3486 - val_loss: -0.0629\n",
            "Epoch 127/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4227 - loss: -0.0728 - val_accuracy: 0.3486 - val_loss: -0.0678\n",
            "Epoch 128/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4584 - loss: -0.0675 - val_accuracy: 0.3486 - val_loss: -0.0728\n",
            "Epoch 129/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4049 - loss: -0.0019 - val_accuracy: 0.3486 - val_loss: -0.0779\n",
            "Epoch 130/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4538 - loss: -0.1178 - val_accuracy: 0.3486 - val_loss: -0.0828\n",
            "Epoch 131/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4420 - loss: 0.0372 - val_accuracy: 0.3486 - val_loss: -0.0881\n",
            "Epoch 132/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4121 - loss: 0.0140 - val_accuracy: 0.3486 - val_loss: -0.0931\n",
            "Epoch 133/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4435 - loss: -0.1012 - val_accuracy: 0.3486 - val_loss: -0.0981\n",
            "Epoch 134/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4638 - loss: 0.0070 - val_accuracy: 0.3486 - val_loss: -0.1032\n",
            "Epoch 135/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4441 - loss: -0.2206 - val_accuracy: 0.3486 - val_loss: -0.1084\n",
            "Epoch 136/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4560 - loss: -0.0065 - val_accuracy: 0.3486 - val_loss: -0.1136\n",
            "Epoch 137/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4383 - loss: -0.0064 - val_accuracy: 0.3486 - val_loss: -0.1188\n",
            "Epoch 138/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4422 - loss: 0.0016 - val_accuracy: 0.3486 - val_loss: -0.1236\n",
            "Epoch 139/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4769 - loss: -0.1146 - val_accuracy: 0.3486 - val_loss: -0.1287\n",
            "Epoch 140/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4365 - loss: -0.0254 - val_accuracy: 0.3486 - val_loss: -0.1339\n",
            "Epoch 141/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4300 - loss: -0.1008 - val_accuracy: 0.3486 - val_loss: -0.1389\n",
            "Epoch 142/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4051 - loss: -0.0346 - val_accuracy: 0.3486 - val_loss: -0.1442\n",
            "Epoch 143/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4214 - loss: -0.0617 - val_accuracy: 0.3486 - val_loss: -0.1492\n",
            "Epoch 144/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4588 - loss: -0.0768 - val_accuracy: 0.3486 - val_loss: -0.1542\n",
            "Epoch 145/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4459 - loss: -0.0696 - val_accuracy: 0.3486 - val_loss: -0.1593\n",
            "Epoch 146/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4473 - loss: -0.0666 - val_accuracy: 0.3486 - val_loss: -0.1647\n",
            "Epoch 147/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4043 - loss: -0.1246 - val_accuracy: 0.3486 - val_loss: -0.1697\n",
            "Epoch 148/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4606 - loss: 0.0034 - val_accuracy: 0.3486 - val_loss: -0.1749\n",
            "Epoch 149/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4432 - loss: -0.0746 - val_accuracy: 0.3486 - val_loss: -0.1799\n",
            "Epoch 150/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4574 - loss: -0.1284 - val_accuracy: 0.3486 - val_loss: -0.1852\n",
            "Epoch 151/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4013 - loss: -0.2459 - val_accuracy: 0.3486 - val_loss: -0.1898\n",
            "Epoch 152/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4605 - loss: -0.1859 - val_accuracy: 0.3486 - val_loss: -0.1949\n",
            "Epoch 153/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3961 - loss: -0.1738 - val_accuracy: 0.3486 - val_loss: -0.2002\n",
            "Epoch 154/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4291 - loss: -0.0711 - val_accuracy: 0.3486 - val_loss: -0.2053\n",
            "Epoch 155/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4379 - loss: -0.2190 - val_accuracy: 0.3486 - val_loss: -0.2104\n",
            "Epoch 156/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4368 - loss: -0.1813 - val_accuracy: 0.3486 - val_loss: -0.2155\n",
            "Epoch 157/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4587 - loss: -0.2272 - val_accuracy: 0.3486 - val_loss: -0.2206\n",
            "Epoch 158/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4174 - loss: -0.0551 - val_accuracy: 0.3486 - val_loss: -0.2252\n",
            "Epoch 159/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4599 - loss: 0.0052 - val_accuracy: 0.3486 - val_loss: -0.2299\n",
            "Epoch 160/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4435 - loss: -0.2186 - val_accuracy: 0.3486 - val_loss: -0.2352\n",
            "Epoch 161/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4446 - loss: -0.1987 - val_accuracy: 0.3486 - val_loss: -0.2403\n",
            "Epoch 162/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4631 - loss: -0.2295 - val_accuracy: 0.3486 - val_loss: -0.2451\n",
            "Epoch 163/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4386 - loss: -0.3703 - val_accuracy: 0.3486 - val_loss: -0.2499\n",
            "Epoch 164/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4182 - loss: -0.1495 - val_accuracy: 0.3486 - val_loss: -0.2548\n",
            "Epoch 165/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4044 - loss: -0.2534 - val_accuracy: 0.3486 - val_loss: -0.2596\n",
            "Epoch 166/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4503 - loss: -0.1092 - val_accuracy: 0.3486 - val_loss: -0.2646\n",
            "Epoch 167/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4518 - loss: -0.2815 - val_accuracy: 0.3486 - val_loss: -0.2701\n",
            "Epoch 168/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4195 - loss: -0.2329 - val_accuracy: 0.3486 - val_loss: -0.2752\n",
            "Epoch 169/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4483 - loss: -0.2872 - val_accuracy: 0.3486 - val_loss: -0.2802\n",
            "Epoch 170/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4322 - loss: -0.2878 - val_accuracy: 0.3486 - val_loss: -0.2854\n",
            "Epoch 171/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4135 - loss: -0.3700 - val_accuracy: 0.3486 - val_loss: -0.2908\n",
            "Epoch 172/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4335 - loss: -0.2795 - val_accuracy: 0.3486 - val_loss: -0.2956\n",
            "Epoch 173/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4679 - loss: -0.0626 - val_accuracy: 0.3486 - val_loss: -0.3013\n",
            "Epoch 174/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4780 - loss: -0.1318 - val_accuracy: 0.3486 - val_loss: -0.3066\n",
            "Epoch 175/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4408 - loss: -0.1088 - val_accuracy: 0.3486 - val_loss: -0.3121\n",
            "Epoch 176/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4250 - loss: -0.2518 - val_accuracy: 0.3486 - val_loss: -0.3170\n",
            "Epoch 177/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4576 - loss: -0.1130 - val_accuracy: 0.3486 - val_loss: -0.3221\n",
            "Epoch 178/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4564 - loss: -0.2687 - val_accuracy: 0.3486 - val_loss: -0.3275\n",
            "Epoch 179/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4387 - loss: -0.2752 - val_accuracy: 0.3486 - val_loss: -0.3332\n",
            "Epoch 180/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4469 - loss: -0.1988 - val_accuracy: 0.3486 - val_loss: -0.3387\n",
            "Epoch 181/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4498 - loss: -0.3835 - val_accuracy: 0.3486 - val_loss: -0.3437\n",
            "Epoch 182/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4203 - loss: -0.2793 - val_accuracy: 0.3486 - val_loss: -0.3491\n",
            "Epoch 183/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4411 - loss: -0.3225 - val_accuracy: 0.3486 - val_loss: -0.3545\n",
            "Epoch 184/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4456 - loss: -0.2648 - val_accuracy: 0.3486 - val_loss: -0.3596\n",
            "Epoch 185/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4230 - loss: -0.1700 - val_accuracy: 0.3486 - val_loss: -0.3649\n",
            "Epoch 186/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4591 - loss: -0.1643 - val_accuracy: 0.3486 - val_loss: -0.3697\n",
            "Epoch 187/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4619 - loss: -0.1964 - val_accuracy: 0.3486 - val_loss: -0.3752\n",
            "Epoch 188/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4374 - loss: -0.1533 - val_accuracy: 0.3486 - val_loss: -0.3806\n",
            "Epoch 189/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4521 - loss: -0.2370 - val_accuracy: 0.3486 - val_loss: -0.3856\n",
            "Epoch 190/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4516 - loss: -0.3797 - val_accuracy: 0.3486 - val_loss: -0.3907\n",
            "Epoch 191/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4442 - loss: -0.1653 - val_accuracy: 0.3486 - val_loss: -0.3958\n",
            "Epoch 192/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4523 - loss: -0.3470 - val_accuracy: 0.3486 - val_loss: -0.4014\n",
            "Epoch 193/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4081 - loss: -0.4541 - val_accuracy: 0.3486 - val_loss: -0.4066\n",
            "Epoch 194/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4173 - loss: -0.3057 - val_accuracy: 0.3486 - val_loss: -0.4116\n",
            "Epoch 195/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3894 - loss: -0.3639 - val_accuracy: 0.3486 - val_loss: -0.4172\n",
            "Epoch 196/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4248 - loss: -0.3876 - val_accuracy: 0.3486 - val_loss: -0.4229\n",
            "Epoch 197/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4328 - loss: -0.1851 - val_accuracy: 0.3486 - val_loss: -0.4284\n",
            "Epoch 198/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4046 - loss: -0.3293 - val_accuracy: 0.3486 - val_loss: -0.4338\n",
            "Epoch 199/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4371 - loss: -0.4450 - val_accuracy: 0.3486 - val_loss: -0.4390\n",
            "Epoch 200/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4318 - loss: -0.3643 - val_accuracy: 0.3486 - val_loss: -0.4442\n",
            "Epoch 201/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4194 - loss: -0.4316 - val_accuracy: 0.3486 - val_loss: -0.4501\n",
            "Epoch 202/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4530 - loss: -0.2670 - val_accuracy: 0.3486 - val_loss: -0.4560\n",
            "Epoch 203/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4650 - loss: -0.4059 - val_accuracy: 0.3486 - val_loss: -0.4618\n",
            "Epoch 204/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4139 - loss: -0.4130 - val_accuracy: 0.3486 - val_loss: -0.4675\n",
            "Epoch 205/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4542 - loss: -0.3843 - val_accuracy: 0.3486 - val_loss: -0.4731\n",
            "Epoch 206/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4153 - loss: -0.3556 - val_accuracy: 0.3486 - val_loss: -0.4783\n",
            "Epoch 207/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4369 - loss: -0.2278 - val_accuracy: 0.3486 - val_loss: -0.4836\n",
            "Epoch 208/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4207 - loss: -0.4456 - val_accuracy: 0.3486 - val_loss: -0.4889\n",
            "Epoch 209/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4371 - loss: -0.4982 - val_accuracy: 0.3486 - val_loss: -0.4942\n",
            "Epoch 210/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4522 - loss: -0.3714 - val_accuracy: 0.3486 - val_loss: -0.4997\n",
            "Epoch 211/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4190 - loss: -0.4835 - val_accuracy: 0.3486 - val_loss: -0.5051\n",
            "Epoch 212/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4092 - loss: -0.1799 - val_accuracy: 0.3486 - val_loss: -0.5106\n",
            "Epoch 213/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4300 - loss: -0.2278 - val_accuracy: 0.3486 - val_loss: -0.5164\n",
            "Epoch 214/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4570 - loss: -0.5280 - val_accuracy: 0.3486 - val_loss: -0.5221\n",
            "Epoch 215/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4554 - loss: -0.1130 - val_accuracy: 0.3486 - val_loss: -0.5273\n",
            "Epoch 216/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4232 - loss: -0.4774 - val_accuracy: 0.3486 - val_loss: -0.5331\n",
            "Epoch 217/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4597 - loss: -0.7027 - val_accuracy: 0.3486 - val_loss: -0.5389\n",
            "Epoch 218/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4294 - loss: -0.3101 - val_accuracy: 0.3486 - val_loss: -0.5447\n",
            "Epoch 219/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4217 - loss: -0.6666 - val_accuracy: 0.3486 - val_loss: -0.5502\n",
            "Epoch 220/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4762 - loss: -0.1897 - val_accuracy: 0.3486 - val_loss: -0.5564\n",
            "Epoch 221/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4754 - loss: -0.4446 - val_accuracy: 0.3486 - val_loss: -0.5615\n",
            "Epoch 222/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4051 - loss: -0.4527 - val_accuracy: 0.3486 - val_loss: -0.5670\n",
            "Epoch 223/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4567 - loss: -0.4550 - val_accuracy: 0.3486 - val_loss: -0.5728\n",
            "Epoch 224/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4675 - loss: -0.3927 - val_accuracy: 0.3486 - val_loss: -0.5790\n",
            "Epoch 225/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4558 - loss: -0.5676 - val_accuracy: 0.3486 - val_loss: -0.5847\n",
            "Epoch 226/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4489 - loss: -0.7960 - val_accuracy: 0.3486 - val_loss: -0.5908\n",
            "Epoch 227/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4428 - loss: -0.3841 - val_accuracy: 0.3486 - val_loss: -0.5968\n",
            "Epoch 228/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4206 - loss: -0.5549 - val_accuracy: 0.3486 - val_loss: -0.6024\n",
            "Epoch 229/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4808 - loss: -0.4536 - val_accuracy: 0.3486 - val_loss: -0.6081\n",
            "Epoch 230/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4168 - loss: -0.5656 - val_accuracy: 0.3486 - val_loss: -0.6146\n",
            "Epoch 231/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4294 - loss: -0.5700 - val_accuracy: 0.3486 - val_loss: -0.6202\n",
            "Epoch 232/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4101 - loss: -0.5543 - val_accuracy: 0.3486 - val_loss: -0.6260\n",
            "Epoch 233/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4357 - loss: -0.6604 - val_accuracy: 0.3486 - val_loss: -0.6317\n",
            "Epoch 234/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4365 - loss: -1.1078 - val_accuracy: 0.3486 - val_loss: -0.6376\n",
            "Epoch 235/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3935 - loss: -0.7224 - val_accuracy: 0.3486 - val_loss: -0.6435\n",
            "Epoch 236/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3997 - loss: -0.6549 - val_accuracy: 0.3486 - val_loss: -0.6493\n",
            "Epoch 237/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4138 - loss: -0.5165 - val_accuracy: 0.3486 - val_loss: -0.6556\n",
            "Epoch 238/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4368 - loss: -0.4784 - val_accuracy: 0.3486 - val_loss: -0.6614\n",
            "Epoch 239/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4092 - loss: -0.5706 - val_accuracy: 0.3486 - val_loss: -0.6673\n",
            "Epoch 240/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3902 - loss: -0.5287 - val_accuracy: 0.3486 - val_loss: -0.6735\n",
            "Epoch 241/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4043 - loss: -0.6767 - val_accuracy: 0.3486 - val_loss: -0.6790\n",
            "Epoch 242/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4115 - loss: -0.5399 - val_accuracy: 0.3486 - val_loss: -0.6843\n",
            "Epoch 243/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4363 - loss: -0.5997 - val_accuracy: 0.3486 - val_loss: -0.6902\n",
            "Epoch 244/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4310 - loss: -0.7544 - val_accuracy: 0.3486 - val_loss: -0.6960\n",
            "Epoch 245/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4010 - loss: -0.6756 - val_accuracy: 0.3486 - val_loss: -0.7018\n",
            "Epoch 246/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4155 - loss: -0.6124 - val_accuracy: 0.3486 - val_loss: -0.7078\n",
            "Epoch 247/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4425 - loss: -0.7026 - val_accuracy: 0.3486 - val_loss: -0.7142\n",
            "Epoch 248/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4499 - loss: -0.6182 - val_accuracy: 0.3486 - val_loss: -0.7203\n",
            "Epoch 249/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4166 - loss: -0.6975 - val_accuracy: 0.3486 - val_loss: -0.7258\n",
            "Epoch 250/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4476 - loss: -0.6979 - val_accuracy: 0.3486 - val_loss: -0.7316\n",
            "Epoch 251/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4476 - loss: -0.7103 - val_accuracy: 0.3486 - val_loss: -0.7376\n",
            "Epoch 252/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4679 - loss: -0.6984 - val_accuracy: 0.3486 - val_loss: -0.7438\n",
            "Epoch 253/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4691 - loss: -0.6945 - val_accuracy: 0.3486 - val_loss: -0.7499\n",
            "Epoch 254/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4492 - loss: -0.4143 - val_accuracy: 0.3486 - val_loss: -0.7561\n",
            "Epoch 255/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4756 - loss: -0.5098 - val_accuracy: 0.3486 - val_loss: -0.7622\n",
            "Epoch 256/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4565 - loss: -0.5202 - val_accuracy: 0.3486 - val_loss: -0.7683\n",
            "Epoch 257/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4335 - loss: -0.4508 - val_accuracy: 0.3486 - val_loss: -0.7744\n",
            "Epoch 258/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4369 - loss: -0.7402 - val_accuracy: 0.3486 - val_loss: -0.7806\n",
            "Epoch 259/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4432 - loss: -0.4308 - val_accuracy: 0.3486 - val_loss: -0.7870\n",
            "Epoch 260/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4435 - loss: -0.5286 - val_accuracy: 0.3486 - val_loss: -0.7936\n",
            "Epoch 261/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4679 - loss: -0.8894 - val_accuracy: 0.3486 - val_loss: -0.7998\n",
            "Epoch 262/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4354 - loss: -0.7197 - val_accuracy: 0.3486 - val_loss: -0.8063\n",
            "Epoch 263/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4486 - loss: -0.1830 - val_accuracy: 0.3486 - val_loss: -0.8132\n",
            "Epoch 264/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4055 - loss: -0.8894 - val_accuracy: 0.3486 - val_loss: -0.8196\n",
            "Epoch 265/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4681 - loss: -0.6317 - val_accuracy: 0.3486 - val_loss: -0.8262\n",
            "Epoch 266/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4358 - loss: -0.5548 - val_accuracy: 0.3486 - val_loss: -0.8332\n",
            "Epoch 267/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4208 - loss: -0.9030 - val_accuracy: 0.3486 - val_loss: -0.8397\n",
            "Epoch 268/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4070 - loss: -0.9424 - val_accuracy: 0.3486 - val_loss: -0.8459\n",
            "Epoch 269/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4262 - loss: -0.2860 - val_accuracy: 0.3486 - val_loss: -0.8527\n",
            "Epoch 270/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4099 - loss: -1.1500 - val_accuracy: 0.3486 - val_loss: -0.8592\n",
            "Epoch 271/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4429 - loss: -0.6584 - val_accuracy: 0.3486 - val_loss: -0.8659\n",
            "Epoch 272/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4304 - loss: -0.6835 - val_accuracy: 0.3486 - val_loss: -0.8726\n",
            "Epoch 273/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4492 - loss: -0.4312 - val_accuracy: 0.3486 - val_loss: -0.8795\n",
            "Epoch 274/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4243 - loss: -0.7766 - val_accuracy: 0.3486 - val_loss: -0.8853\n",
            "Epoch 275/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4222 - loss: -0.7821 - val_accuracy: 0.3486 - val_loss: -0.8922\n",
            "Epoch 276/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4303 - loss: -1.1551 - val_accuracy: 0.3486 - val_loss: -0.8985\n",
            "Epoch 277/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4279 - loss: -0.7378 - val_accuracy: 0.3486 - val_loss: -0.9051\n",
            "Epoch 278/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4330 - loss: -0.8459 - val_accuracy: 0.3486 - val_loss: -0.9114\n",
            "Epoch 279/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4309 - loss: -1.3840 - val_accuracy: 0.3486 - val_loss: -0.9182\n",
            "Epoch 280/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4492 - loss: -0.9635 - val_accuracy: 0.3486 - val_loss: -0.9248\n",
            "Epoch 281/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4442 - loss: -0.6811 - val_accuracy: 0.3486 - val_loss: -0.9318\n",
            "Epoch 282/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4233 - loss: -0.9990 - val_accuracy: 0.3486 - val_loss: -0.9385\n",
            "Epoch 283/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4525 - loss: -0.7114 - val_accuracy: 0.3486 - val_loss: -0.9449\n",
            "Epoch 284/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4537 - loss: -0.7035 - val_accuracy: 0.3486 - val_loss: -0.9512\n",
            "Epoch 285/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4088 - loss: -0.8522 - val_accuracy: 0.3486 - val_loss: -0.9583\n",
            "Epoch 286/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4369 - loss: -0.9263 - val_accuracy: 0.3486 - val_loss: -0.9653\n",
            "Epoch 287/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4236 - loss: -0.4240 - val_accuracy: 0.3486 - val_loss: -0.9725\n",
            "Epoch 288/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4288 - loss: -0.9354 - val_accuracy: 0.3486 - val_loss: -0.9793\n",
            "Epoch 289/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4311 - loss: -0.9108 - val_accuracy: 0.3486 - val_loss: -0.9866\n",
            "Epoch 290/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4682 - loss: -0.5704 - val_accuracy: 0.3486 - val_loss: -0.9928\n",
            "Epoch 291/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4494 - loss: -1.1491 - val_accuracy: 0.3486 - val_loss: -0.9995\n",
            "Epoch 292/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4016 - loss: -0.9714 - val_accuracy: 0.3486 - val_loss: -1.0062\n",
            "Epoch 293/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4377 - loss: -0.8736 - val_accuracy: 0.3486 - val_loss: -1.0133\n",
            "Epoch 294/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4116 - loss: -0.9327 - val_accuracy: 0.3486 - val_loss: -1.0202\n",
            "Epoch 295/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4578 - loss: -0.9481 - val_accuracy: 0.3486 - val_loss: -1.0267\n",
            "Epoch 296/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4604 - loss: -0.9895 - val_accuracy: 0.3486 - val_loss: -1.0333\n",
            "Epoch 297/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4626 - loss: -1.1056 - val_accuracy: 0.3486 - val_loss: -1.0404\n",
            "Epoch 298/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4236 - loss: -1.2338 - val_accuracy: 0.3486 - val_loss: -1.0474\n",
            "Epoch 299/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4323 - loss: -0.8115 - val_accuracy: 0.3486 - val_loss: -1.0544\n",
            "Epoch 300/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4003 - loss: -0.8736 - val_accuracy: 0.3486 - val_loss: -1.0618\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3207 - loss: -1.3178\n",
            "Test Accuracy: 0.3486\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Confusion Matrix:\n",
            " [[ 0 29  0]\n",
            " [ 1 38  0]\n",
            " [ 0 41  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        29\n",
            "           1       0.35      0.97      0.52        39\n",
            "           2       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.35       109\n",
            "   macro avg       0.12      0.32      0.17       109\n",
            "weighted avg       0.13      0.35      0.18       109\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Load dataset (You need to manually download and provide the correct path)\n",
        "dataset_path = \"/content/Housing (2).csv\"  # Change this after downloading\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Convert categorical values into numerical (if any exist)\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "# Assuming the last column is the target variable\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build ANN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(12, activation='swish', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(25, activation='swish'),\n",
        "    tf.keras.layers.Dense(15, activation='swish'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    }
  ]
}